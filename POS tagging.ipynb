{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.corpus import brown\n",
        "nltk.download('brown')\n",
        "import numpy as np\n",
        "from numba import njit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6KObsJQY4Mwi"
      },
      "source": [
        "# Hidden Markov Model\n",
        "|||\n",
        "|---|---|\n",
        "| $Q=q_1q_2\\dots q_N$ | a set of N states|\n",
        "| $A=a_{11}\\dots a_{ij}\\dots a_{NN}$ | a transition probability matrix $A$, each $a_{ij}$ representing the probability of moving from state $i$ to state $j$, s.t. $\\sum_{j=1}^N a_{ij} = 1 \\ \\forall i$|\n",
        "| $B=b_i(o_t)$ | a sequence of observation likelihoods, also called emission probabilities, each expressing the probability of an observation $o_t$ (drawn from a vocabulary $V = v_1, v_2, \\dots, v_V$) being generated from a state $q_i$|\n",
        "|$\\pi = \\pi_1, \\pi_2, \\dots, \\pi_N$| an initial probability distribution over states. $\\pi_i$ is the probability that the Markov chain will start in state $i$. Some states $j$ may have $\\pi_j = 0$, meaning that they cannot be initial states. Also, $\\sum_{i=1}^N \\pi_i = 1$|\n",
        "\n",
        "\n",
        "\n",
        "# Calculating prior probabilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "words = list(set(brown.words()))\n",
        "pos_tags = ['PRON', 'VERB', 'CONJ', '.', 'X', 'DET', 'NUM', 'ADJ', 'ADV', 'ADP', 'PRT', 'NOUN'] \n",
        "# pos_tags = list(set(pair[1] for pair in brown.tagged_words(tagset='universal')))\n",
        "tagged_sents = list(brown.tagged_sents(tagset='universal'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def to_numpy(XY:list[list[tuple[str,str]]], X_name:list, Y_name:list, to_sort=False):\n",
        "    X_id_map = {v: i for i, v in enumerate(X_name)}\n",
        "    Y_id_map = {v: i for i, v in enumerate(Y_name)}\n",
        "    if to_sort: XY = sorted(XY,key=len)\n",
        "        \n",
        "    n = len(XY)\n",
        "    m = max(len(s) for s in XY)\n",
        "    ST = np.zeros((n, m, 2), dtype=np.int32)-1\n",
        "\n",
        "    for i, s in enumerate(XY):\n",
        "        for j, w in enumerate(s):\n",
        "            ST[i, j] = np.array([X_id_map[w[0]], Y_id_map[w[1]]])\n",
        "\n",
        "    return ST\n",
        "\n",
        "ST = to_numpy(tagged_sents, words, pos_tags)\n",
        "# print(ST)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@njit\n",
        "def get_prob(stB:np.ndarray, no_words:int, no_tags:int, eps:float=0.00001):\n",
        "    A = np.zeros((no_tags,no_tags), dtype=np.float64)\n",
        "    B = np.zeros((no_tags,no_words), dtype=np.float64)\n",
        "    Pi = np.zeros(no_tags, dtype=np.float64)\n",
        "\n",
        "    m, n, _ = stB.shape\n",
        "    \n",
        "    for i in range(m):\n",
        "        if stB[i,0,0] == -1 : break\n",
        "        Pi[stB[i,0,1]] += 1\n",
        "        for j in range(n-1):\n",
        "            wnth = stB[i,j,0]\n",
        "            nth, nnth = stB[i,j:j+2,1]\n",
        "            B[nth, wnth] += 1\n",
        "            if nnth == -1 : break\n",
        "            A[nth,nnth] += 1\n",
        "        if nnth != -1 : B[stB[i,n-1,1], stB[i,n-1,0]] += 1\n",
        "    A /= np.sum(A,axis=1).reshape(-1,1) + eps\n",
        "    B /= np.sum(B,axis=1).reshape(-1,1) + eps\n",
        "    Pi /= np.sum(Pi) + eps\n",
        "    return A, B, Pi\n",
        "\n",
        "A, B, Pi = get_prob(ST, len(words), len(pos_tags))\n",
        "# print(A)\n",
        "# print(B)\n",
        "# print(Pi)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9oGBGjq4Mwk"
      },
      "source": [
        "# Viterbi parameters\n",
        "|||\n",
        "|---|---|\n",
        " |$v_{t-1}(i)$ | the previous Viterbi path probability from the previous time step|\n",
        " |$a_{ij}$ | the transition probability from previous state $q_i$ to current state $q_j$|\n",
        " |$b_j(o_t)$| the state observation likelihood of the observation symbol $o_t$ given the current state $j$|"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Observation sequence:   O  =  ['Catcher', 'Frank', \"House's\", 'throw', 'in', 'an', 'effort', 'to', 'nab', 'Throneberry', 'was', 'wide', 'and', 'in', 'the', 'dirt', '.']\n",
            "Correct state sequence: S* =  ['NOUN', 'NOUN', 'NOUN', 'NOUN', 'ADP', 'DET', 'NOUN', 'PRT', 'VERB', 'NOUN', 'VERB', 'ADV', 'CONJ', 'ADP', 'DET', 'NOUN', '.']\n",
            "Optimal state sequence: S  =  ['NOUN', 'NOUN', 'NOUN', 'VERB', 'ADP', 'DET', 'NOUN', 'PRT', 'VERB', 'NOUN', 'VERB', 'ADJ', 'CONJ', 'ADP', 'DET', 'NOUN', '.']\n",
            "Do they match ? :  False\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>throw</th>\n",
              "      <th>wide</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Correct</th>\n",
              "      <td>NOUN</td>\n",
              "      <td>ADV</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Guessed</th>\n",
              "      <td>VERB</td>\n",
              "      <td>ADJ</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        throw wide\n",
              "Correct  NOUN  ADV\n",
              "Guessed  VERB  ADJ"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from viterbi import viterbi_log\n",
        "\n",
        "# ST = to_numpy(tagged_sents, words, pos_tags)\n",
        "# A, B, Pi = get_prob(ST, len(words), len(pos_tags))\n",
        "\n",
        "r = 1028              # sample number to test\n",
        "test_sent = []\n",
        "test_tags = []\n",
        "for word, tag in tagged_sents[r]:\n",
        "    test_sent.append(word)\n",
        "    test_tags.append(tag)\n",
        "O = [words.index(word) for word in test_sent] # producing observation states (words) in terms of its word index\n",
        "# correct_tag_seq = np.array([pos_tags.index(pair[1]) for pair in brown.tagged_sents()[r]])\n",
        "\n",
        "optim_state_seq, log_prob_trellis, backtrack_matrix = viterbi_log(A,Pi,B,O)\n",
        "\n",
        "optim_state_seq = [pos_tags[t] for t in optim_state_seq]\n",
        "\n",
        "# The following was to check if it was working or not. These parts need to be better done.\n",
        "print('Observation sequence:   O  = ', test_sent)\n",
        "print('Correct state sequence: S* = ', test_tags)\n",
        "print('Optimal state sequence: S  = ', optim_state_seq)\n",
        "print(\"Do they match ? : \", test_tags==optim_state_seq)\n",
        "\n",
        "from pandas import DataFrame\n",
        "test_result_df = DataFrame(index=test_sent,columns=['Correct','Guessed'],data=zip(test_tags,optim_state_seq)).T\n",
        "test_result_df.iloc[:,(test_result_df.nunique()!=1).values]"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
