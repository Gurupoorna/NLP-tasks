{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pycrfsuite\n",
    "from itertools import chain\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definig features of CRF model\n",
    "\n",
    "Putting in features for each word, like ends with 'ly', 'ing', 'ed', etc. Or is it starting with capital letter and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "    features = [\n",
    "        'bias',\n",
    "        'word.lower=' + word.lower(),\n",
    "        'word[-3:]=' + word[-3:],\n",
    "        'word[-2:]=' + word[-2:],\n",
    "        'word.isupper=%s' % word.isupper(),\n",
    "        'word.istitle=%s' % word.istitle(),\n",
    "        'word.isdigit=%s' % word.isdigit(),\n",
    "    ]\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        features.extend([\n",
    "            '-1:word.lower=' + word1.lower(),\n",
    "            '-1:word.istitle=%s' % word1.istitle(),\n",
    "            '-1:word.isupper=%s' % word1.isupper(),\n",
    "        ])\n",
    "    else:\n",
    "        features.append('BOS')\n",
    "        \n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        features.extend([\n",
    "            '+1:word.lower=' + word1.lower(),\n",
    "            '+1:word.istitle=%s' % word1.istitle(),\n",
    "            '+1:word.isupper=%s' % word1.isupper(),\n",
    "        ])\n",
    "    else:\n",
    "        features.append('EOS')\n",
    "                \n",
    "    return features\n",
    "\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2postags(sent):\n",
    "    return [postag for token, postag in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, postag in sent]    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset\n",
    "\n",
    "Load sentences and split into train and test sentences (<b>60-40 split currently, needs changes!</b>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_dataset = brown.tagged_sents(tagset='universal')\n",
    "train_sents, test_sents = train_test_split(sent_dataset, test_size=0.4, shuffle=True, random_state=100)\n",
    "X_train = [sent2features(s) for s in train_sents]\n",
    "y_train = [sent2postags(s) for s in train_sents]\n",
    "\n",
    "X_test = [sent2features(s) for s in test_sents]\n",
    "y_test = [sent2postags(s) for s in test_sents]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "Creating `trainer` object and loading it with the feature data constructed above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pycrfsuite.Trainer(verbose=False)\n",
    "\n",
    "for xseq, yseq in zip(X_train, y_train):\n",
    "    trainer.append(xseq, yseq)\n",
    "\n",
    "trainer.set_params({\n",
    "    'c1': 1.0,   # coefficient for L1 penalty\n",
    "    'c2': 1e-3,  # coefficient for L2 penalty\n",
    "    'max_iterations': 50,  # stop earlier\n",
    "\n",
    "    # include transitions that are possible, but not observed\n",
    "    'feature.possible_transitions': True\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model and save into 'browncorpus.crfsuite' file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num': 50,\n",
       " 'scores': {},\n",
       " 'loss': 66580.174147,\n",
       " 'feature_norm': 241.602197,\n",
       " 'error_norm': 5043.937762,\n",
       " 'active_features': 20190,\n",
       " 'linesearch_trials': 1,\n",
       " 'linesearch_step': 1.0,\n",
       " 'time': 0.882}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train('browncorpus.crfsuite')\n",
    "trainer.logparser.last_iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference\n",
    "\n",
    "Example sentence tagging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Manchester Guardian wondered how anyone in a railway carriage would have an opportunity to talk to Mr. Lewis , since it was well known that Mr. Lewis always did all of the talking .\n",
      "\n",
      "Predicted: DET NOUN NOUN VERB ADV NOUN ADP DET NOUN NOUN VERB VERB DET NOUN PRT VERB ADP NOUN NOUN . ADP PRON VERB ADV VERB ADP NOUN NOUN ADV VERB PRT ADP DET VERB .\n",
      "Correct:   DET NOUN NOUN VERB ADV NOUN ADP DET NOUN NOUN VERB VERB DET NOUN PRT VERB ADP NOUN NOUN . ADP PRON VERB ADV VERB ADP NOUN NOUN ADV VERB PRT ADP DET VERB .\n"
     ]
    }
   ],
   "source": [
    "tagger = pycrfsuite.Tagger()\n",
    "tagger.open('browncorpus.crfsuite')\n",
    "example_sent = test_sents[345]\n",
    "print(' '.join(sent2tokens(example_sent)), end='\\n\\n')\n",
    "\n",
    "print(\"Predicted:\", ' '.join(tagger.tag(sent2features(example_sent))))\n",
    "print(\"Correct:  \", ' '.join(sent2postags(example_sent)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "Calculate precision, recall and f1-score tagwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classification_report(y_true, y_pred):\n",
    "    lb = LabelBinarizer()\n",
    "    y_true_combined = lb.fit_transform(list(chain.from_iterable(y_true)))\n",
    "    y_pred_combined = lb.transform(list(chain.from_iterable(y_pred)))\n",
    "\n",
    "    tagset = lb.classes_\n",
    "    return classification_report(\n",
    "        y_true_combined,\n",
    "        y_pred_combined,\n",
    "        labels = range(len(tagset)),\n",
    "        target_names = tagset,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test set evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = [tagger.tag(xseq) for xseq in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           .       1.00      1.00      1.00     59144\n",
      "         ADJ       0.94      0.90      0.92     33448\n",
      "         ADP       0.98      0.98      0.98     58138\n",
      "         ADV       0.93      0.94      0.93     22620\n",
      "        CONJ       0.99      1.00      1.00     15153\n",
      "         DET       0.99      1.00      0.99     55068\n",
      "        NOUN       0.97      0.97      0.97    110169\n",
      "         NUM       0.97      0.97      0.97      5881\n",
      "        PRON       0.99      0.99      0.99     19772\n",
      "         PRT       0.93      0.94      0.94     11815\n",
      "        VERB       0.97      0.97      0.97     73106\n",
      "           X       0.79      0.35      0.48       605\n",
      "\n",
      "   micro avg       0.97      0.97      0.97    464919\n",
      "   macro avg       0.95      0.92      0.93    464919\n",
      "weighted avg       0.97      0.97      0.97    464919\n",
      " samples avg       0.97      0.97      0.97    464919\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(get_classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NOUN</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>ADP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NOUN</th>\n",
       "      <td>107356</td>\n",
       "      <td>1272</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADJ</th>\n",
       "      <td>1498</td>\n",
       "      <td>30210</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADP</th>\n",
       "      <td>55</td>\n",
       "      <td>20</td>\n",
       "      <td>56806</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        NOUN    ADJ    ADP\n",
       "NOUN  107356   1272     16\n",
       "ADJ     1498  30210     24\n",
       "ADP       55     20  56806"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true_combined = list(chain.from_iterable(y_test))\n",
    "y_pred_combined = list(chain.from_iterable(y_pred))\n",
    "\n",
    "tags_of_interest = ['NOUN','ADJ','ADP',]\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(\n",
    "    confusion_matrix(y_true_combined, y_pred_combined, labels=tags_of_interest),\n",
    "    columns=tags_of_interest,\n",
    "    index=tags_of_interest\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaarya",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
